{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 297,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10101010101010101,
      "grad_norm": 7.60196590423584,
      "learning_rate": 4.848484848484849e-05,
      "loss": 1.4122,
      "step": 10
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 4.997495174407959,
      "learning_rate": 4.68013468013468e-05,
      "loss": 1.401,
      "step": 20
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 6.694113731384277,
      "learning_rate": 4.511784511784512e-05,
      "loss": 1.4093,
      "step": 30
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 6.1419219970703125,
      "learning_rate": 4.343434343434344e-05,
      "loss": 1.307,
      "step": 40
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 16.874704360961914,
      "learning_rate": 4.175084175084175e-05,
      "loss": 1.1954,
      "step": 50
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 10.991486549377441,
      "learning_rate": 4.006734006734007e-05,
      "loss": 1.1069,
      "step": 60
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 9.965495109558105,
      "learning_rate": 3.838383838383838e-05,
      "loss": 0.9825,
      "step": 70
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 12.58952522277832,
      "learning_rate": 3.6700336700336704e-05,
      "loss": 0.8282,
      "step": 80
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 19.845046997070312,
      "learning_rate": 3.501683501683502e-05,
      "loss": 0.9846,
      "step": 90
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 6.90363073348999,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.8957,
      "step": 100
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 72.1224136352539,
      "learning_rate": 3.164983164983165e-05,
      "loss": 1.1621,
      "step": 110
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 14.47693920135498,
      "learning_rate": 2.996632996632997e-05,
      "loss": 1.0749,
      "step": 120
    },
    {
      "epoch": 1.3131313131313131,
      "grad_norm": 12.183195114135742,
      "learning_rate": 2.8282828282828282e-05,
      "loss": 0.7209,
      "step": 130
    },
    {
      "epoch": 1.4141414141414141,
      "grad_norm": 12.38217830657959,
      "learning_rate": 2.65993265993266e-05,
      "loss": 0.575,
      "step": 140
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 4.831153869628906,
      "learning_rate": 2.4915824915824916e-05,
      "loss": 0.5279,
      "step": 150
    },
    {
      "epoch": 1.6161616161616161,
      "grad_norm": 1.3945575952529907,
      "learning_rate": 2.3232323232323232e-05,
      "loss": 0.365,
      "step": 160
    },
    {
      "epoch": 1.7171717171717171,
      "grad_norm": 39.24291229248047,
      "learning_rate": 2.1548821548821547e-05,
      "loss": 0.7486,
      "step": 170
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 24.562978744506836,
      "learning_rate": 1.9865319865319866e-05,
      "loss": 0.8711,
      "step": 180
    },
    {
      "epoch": 1.9191919191919191,
      "grad_norm": 24.674184799194336,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.3188,
      "step": 190
    },
    {
      "epoch": 2.0202020202020203,
      "grad_norm": 46.4881477355957,
      "learning_rate": 1.6498316498316498e-05,
      "loss": 0.8191,
      "step": 200
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 0.8214201927185059,
      "learning_rate": 1.4814814814814815e-05,
      "loss": 0.2741,
      "step": 210
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.48284009099006653,
      "learning_rate": 1.3131313131313134e-05,
      "loss": 0.653,
      "step": 220
    },
    {
      "epoch": 2.323232323232323,
      "grad_norm": 0.34832829236984253,
      "learning_rate": 1.144781144781145e-05,
      "loss": 0.2553,
      "step": 230
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.3219086229801178,
      "learning_rate": 9.764309764309765e-06,
      "loss": 0.5004,
      "step": 240
    },
    {
      "epoch": 2.525252525252525,
      "grad_norm": 0.502259373664856,
      "learning_rate": 8.080808080808082e-06,
      "loss": 0.6195,
      "step": 250
    },
    {
      "epoch": 2.6262626262626263,
      "grad_norm": 1.1117088794708252,
      "learning_rate": 6.397306397306398e-06,
      "loss": 0.2653,
      "step": 260
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 1.7182838916778564,
      "learning_rate": 4.7138047138047145e-06,
      "loss": 0.0917,
      "step": 270
    },
    {
      "epoch": 2.8282828282828283,
      "grad_norm": 96.96827697753906,
      "learning_rate": 3.0303030303030305e-06,
      "loss": 0.3415,
      "step": 280
    },
    {
      "epoch": 2.929292929292929,
      "grad_norm": 28.199552536010742,
      "learning_rate": 1.3468013468013467e-06,
      "loss": 0.3836,
      "step": 290
    }
  ],
  "logging_steps": 10,
  "max_steps": 297,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 311002852073472.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
